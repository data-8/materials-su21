{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw11.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 11: Regression Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Yanay Rosen\n",
    "\n",
    "**Helpful Resource:**\n",
    "- [Python Reference](http://data8.org/su21/python-reference.html): Cheat sheet of helpful array & table methods used in Data 8!\n",
    "\n",
    "**Reading**: \n",
    "* [Inference for Regression](https://www.inferentialthinking.com/chapters/16/Inference_for_Regression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests. Each time you start your server, you will need to execute this cell again to load the tests.\n",
    "\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. **Moreover, throughout this homework and all future ones, please be sure to not re-assign variables throughout the notebook!** For example, if you use `max_temperature` in your answer to one question, do not reassign it later on. Otherwise, you will fail tests that you thought you were passing previously!\n",
    "\n",
    "**Deadline:**\n",
    "\n",
    "This assignment is due Tuesday, August 3 at 11:59 P.M. PDT. Late work will not be accepted as per the [policies](http://data8.org/su21/policies.html) page. \n",
    "\n",
    "**Note: This homework has hidden tests on it. That means even though tests may say 100% passed, doesn't mean your final grade will be 100%. We will be running more tests for correctness once everyone turns in the homework.**\n",
    "\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about how to learn cooperatively.\n",
    "\n",
    "You should start early so that you have time to get help if you're stuck. Office hours are held Monday-Friday. The schedule appears on [http://data8.org/su21/office-hours.html](http://data8.org/su21/office-hours.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. \n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\",\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Regression Inference for the NFL Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework, we will be analyzing the relationship between draft position and success in the NFL. The NFL draft is an annual event in which every NFL team takes turns choosing players that they will add to their team. There are around 200 selections, called \"picks\" made every year, although this number has changed over the years.\n",
    "\n",
    "The `nfl_data` table has five columns, the name of the `Player`, the `Salary` that player made for the 2019 season, the year that player was drafted (`Year Drafted`), the number of the draft pick that was used when the player was drafted (`Pick Number`), and the `Position` in football that player plays.\n",
    "\n",
    "Each row in `nfl_data` corresponds to one player who played in the **2019 season**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl_data = Table.read_table(\"nfl.csv\")\n",
    "nfl_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Take the `nfl_data` table and add a column called `Career Length` that corresponds to how long a player has been in the NFL to create a new table called `nfl`. `Career Length` is from when they were drafted to this year, 2021. So, if a player was drafted in 2015, their career length is 6:\n",
    "$$2021-2015=6$$\n",
    "\n",
    "**(3 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_1\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "for_assignment_type": "student"
   },
   "outputs": [],
   "source": [
    "nfl = ...\n",
    "nfl.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, let's investigate our data visually before analyzing it numerically. The first relationship we will analyze is the relationship between a player's `Pick Number` and their `Career Length`. Run the following cell to see a scatter diagram with the line of best fit plotted for you in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell\n",
    "nfl.scatter(\"Pick Number\", \"Career Length\")\n",
    "m, b = np.polyfit(nfl.column(3), nfl.column(5), 1)\n",
    "plt.plot(nfl.column(3), m*nfl.column(3)+b, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 2\n",
    "\n",
    "Use the functions given to assign the correlation between `Pick Number` and `Career Length` to `pick_length_correlation`. `correlation` takes in three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`. **(3 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_2\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T09:57:57.365938Z",
     "start_time": "2018-04-04T09:57:57.357879Z"
    },
    "deletable": false
   },
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    return (arr- np.mean(arr)) / np.std(arr)\n",
    "\n",
    "def correlation(tbl, col1, col2):\n",
    "    r = np.mean(standard_units(tbl.column(col1)) * standard_units(tbl.column(col2)))\n",
    "    return r\n",
    "\n",
    "pick_length_correlation = ...\n",
    "pick_length_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a negative association between `Pick Number` and `Career Length`! If in the sample, we found a linear relation between the two variables, would the same be true for the population? Would it be exactly the same linear relation? Could we predict the response of a new individual who is not in our sample? \n",
    "\n",
    "Let's find out the answers to these questions by investigating whether there is a true linear relation or correlation in the population between `Pick Number` and `Career Length`!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 3\n",
    "\n",
    "Evan thinks that the slope of the true line of best fit for `Pick Number` and `Career Length` is not zero: that is, there is some correlation/association between `Pick Number` and `Career Length`. To test this claim, we can run a hypothesis test! Define the null and alternative hypothesis for this test. **(4 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_3\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 4\n",
    "\n",
    "Saurav says that instead of finding the slope for each resample, we can find the correlation instead, and that we will get the same result for the hypothesis test. Why is he correct? What is the relationship between slope and correlation? **(4 Points)**\n",
    "\n",
    "*Hint: This [section](https://www.inferentialthinking.com/chapters/15/2/Regression_Line.html) of the textbook describes the relationship between slope and correlation.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_4\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 5\n",
    "Define the function `one_resample_r` that performs a bootstrap and finds the correlation between `Pick Number` and `Career Length` in the resample. `one_resample_r` should take three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`. **(5 Points)**\n",
    "\n",
    "*Hint: You can use previously defined functions to help you.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_5\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "manual_problem_id": "crypto_5"
   },
   "outputs": [],
   "source": [
    "def one_resample_r(tbl, col1, col2):\n",
    "    ...\n",
    "\n",
    "# Don't change this line below!\n",
    "one_resample = one_resample_r(nfl, \"Pick Number\", \"Career Length\")\n",
    "one_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 6\n",
    "\n",
    "Generate 1000 bootstrapped correlations for `Pick Number` and `Career Length`, store your results in the array `resampled_correlations_pc`, and plot a histogram of your results. **(5 Points)**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_6\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_correlations_pc = ...\n",
    "...\n",
    "\n",
    "# Don't change the following line of code. It will plot your histogram.\n",
    "Table().with_column(\"Resampled Correlations, Pick Number vs Career Length\", resampled_correlations_pc).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 7\n",
    "\n",
    "Calculate a 95% confidence interval for the resampled correlations. Then, assign `reject` to either `True` if we can reject the null hypothesis, or `False` if we cannot reject the null hypothesis using a 5% p-value cutoff. **(4 Points)**\n",
    " \n",
    "*Note: Feel free to calculate the CI first, then fill in the `reject` variable after.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_7\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_pc = ...\n",
    "upper_bound_pc = ...\n",
    "reject = ...\n",
    "\n",
    "# Don't change this!\n",
    "print(f\"95% CI: [{lower_bound_pc}, {upper_bound_pc}] , Reject the null: {reject}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the relationship between `Pick Number` and `Salary`. As usual, let's inspect our data visually first. A line of best fit is plotted for you in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl.scatter(\"Pick Number\", \"Salary\")\n",
    "c, d = np.polyfit(nfl.column(3), nfl.column(1), 1)\n",
    "plt.plot(nfl.column(3), c*nfl.column(3)+d, color='r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 8\n",
    "\n",
    "Using the function `correlation`, find the correlation between `Pick Number` and `Salary` and assign it to `pick_salary_correlation`. **(3 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_8\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_salary_correlation = ...\n",
    "pick_salary_correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is a negative association between `Pick Number` and `Salary`! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 9\n",
    "\n",
    "Once again, Evan thinks that the slope of the true line of best fit for `Pick Number` and `Salary` is not zero: that is, there is some correlation/association between `Pick Number` and `Salary`. To test this claim, we can run a hypothesis test! Define the null and alternative hypothesis for this test. **(4 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_9\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 10\n",
    "\n",
    "Generate 1000 bootstrapped correlations for `Pick Number` and `Salary`, append them to the array `resampled_correlations_salary`, and then plot a histogram of your results. **(5 Points)**\n",
    "\n",
    "*Hint: Your code for this question will be similar to Question 6.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_10\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_correlations_salary = ...\n",
    "...\n",
    "\n",
    "# Don't change the following line of code. It will plot your histogram.\n",
    "Table().with_column(\"Resampled Correlations for Salary\", resampled_correlations_salary).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 11\n",
    "\n",
    "Calculate a 95% confidence interval for the resampled correlations and then assign either `True` or `False` to `reject_sal` if we can reject the null hypothesis or if we cannot reject the null hypothesis using a 5% p-value cutoff. **(5 Points)**\n",
    "\n",
    "*Note: Feel free to calculate the CI first, then fill in the `reject_sal` variable after.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_11\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 5\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_sal = ...\n",
    "upper_bound_sal = ...\n",
    "reject_sal = ...\n",
    "\n",
    "# Don't change this!\n",
    "print(f\"95% CI: [{lower_bound_sal}, {upper_bound_sal}], Reject the null: {reject_sal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Analyzing Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Evan wants to predict his Career Length and Salary based on his Pick Number. To understand what his Career Length and Salary might be, Evan wants to generate confidence intervals of possible values for both career length and salary. First, let's investigate how effective our predictions for career length and salary based on pick number are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 12\n",
    "\n",
    "Calculate the slope and intercept for the line of best fit for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`. Assign these values to `career_length_slope`, `career_length_intercept`, `salary_slope`, and `salary_intercept` respectively. The function `parameters` returns a two-item array containing the slope and intercept of a linear regression line. **(7 Points)**\n",
    "\n",
    "*Hint 1: Use the `parameters` function with the arguments specified!*\n",
    "\n",
    "*Hint 2: Remember we're predicting career length and salary **based off** a pick number. That should tell you what the `colx` and `coly` arguments you should specify when calling `parameters`.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_12\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 7\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DON'T EDIT THE PARAMETERS FUNCTION\n",
    "def parameters(tbl, colx, coly):\n",
    "    x = tbl.column(colx)\n",
    "    y = tbl.column(coly)\n",
    "    \n",
    "    r = correlation(tbl, colx, coly)\n",
    "    \n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    x_sd = np.std(x)\n",
    "    y_sd = np.std(y)\n",
    "    \n",
    "    slope = (y_sd / x_sd) * r\n",
    "    intercept = y_mean - (slope * x_mean)\n",
    "    return make_array(slope, intercept)\n",
    "\n",
    "career_length_slope = ...\n",
    "career_length_intercept = ...\n",
    "\n",
    "salary_slope = ...\n",
    "salary_intercept = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 13\n",
    "\n",
    "Draw a scatter plot of the residuals (i.e. actual - predicted) for each line of best fit for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`. **(6 Points)**\n",
    "\n",
    "*Hint: We want to get the predictions for every player in the dataset*\n",
    "\n",
    "*Hint 2: This question is really involved, try to follow the skeleton code! This [section](https://www.inferentialthinking.com/chapters/15/5/Visual_Diagnostics.html) of the textbook will be helpful for the next two questions.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_13\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_career_lengths = ...\n",
    "predicted_salaries = ...\n",
    "\n",
    "career_length_residuals = ...\n",
    "salary_residuals = ...\n",
    "\n",
    "nfl_with_residuals = nfl.with_columns(\"Career Length Residuals\", career_length_residuals, \"Salary Residuals\", salary_residuals)\n",
    "\n",
    "# Now generate two scatter plots!\n",
    "nfl_with_residuals.scatter(\"Pick Number\", \"Career Length Residuals\")\n",
    "nfl_with_residuals.scatter(\"Pick Number\", \"Salary Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "Here's a [link](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html) to properties of residuals in the textbook that could help out with some questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 14\n",
    "\n",
    "Based on these plots of residuals, do you think linear regression is a good model for `Pick Number` vs `Career Length` and for `Pick Number` vs `Salary`? Explain for both. **(5 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_14\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 15\n",
    "\n",
    "Assign `career_length_residual_corr` and `salary_residual_corr` to either 1, 2 or 3 corresponding to whether the correlation between `Pick Number` and `Career Length Residuals` is zero, positive, or negative, and to whether the correlation between `Pick Number` and `Salary Residuals` is zero, positive, or negative respectively. **(4 Points)**\n",
    "\n",
    "*Hint: This [section](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html) of the textbook will be helpful.*\n",
    "\n",
    "1. Zero\n",
    "2. Positive\n",
    "3. Negative\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_15\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 2\n",
    " - 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "career_length_residual_corr = ...\n",
    "salary_residual_corr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the largest residuals are positive residuals, so let's investigate those more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 16\n",
    "\n",
    "Let's investigate where our regression line is making errors. Using the `nfl_with_residuals` table, assign `greatest_career_length_residual` to the string that is the name of the player with the largest positive residual for `Pick Number` vs `Career Length`. **(4 Points)**\n",
    "\n",
    "*Hint: We would recommend running `nfl_with_residuals` in a separate cell to see what the table looks like.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_16\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "greatest_career_length_residual = ...\n",
    "greatest_career_length_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's investigate the residuals for salary. Run the cell below to see the players with the largest residuals for `Pick Number` vs `Salary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell!\n",
    "nfl_with_residuals.sort(\"Salary Residuals\", descending=True).take(np.arange(10)).drop(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 17\n",
    "\n",
    "What patterns do you notice with these large residuals for salary? How could this affect our analysis? **(6 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_17\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Part 3: Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Evan wants to predict his career length based on his specific pick number, which is 169. Instead of using the best fit line generated from the sample, Evan wants to generate an interval for his predicted career length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 18\n",
    "\n",
    "Define the function `one_resample_prediction` that generates a bootstrapped sample from the `tbl` argument, calculates the line of best fit for `coly` vs `colx` for that resample, and predicts a value based on `xvalue`. **(6 Points)**\n",
    "\n",
    "*Hint: The standard form of the line of best fit is y = mx+b, with a unique slope (m) and intercept (b) for our data. Remember, the `parameters` function was defined earlier to help find that slope and intercept!*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_18\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_resample_prediction(tbl, colx, coly, xvalue):\n",
    "    ...\n",
    "\n",
    "evans_career_length_pred = one_resample_prediction(nfl, \"Pick Number\", \"Career Length\", 169)\n",
    "evans_career_length_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 19\n",
    "\n",
    "Assign `resampled_predictions` to be an array that will contain 1000 resampled predictions for Evan's career length based on his pick number 169, and then generate a histogram of it. **(5 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_19\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_predictions = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change/delete the code below in this cell\n",
    "Table().with_column(\"Resampled Career Length Predictions\", resampled_predictions).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 20\n",
    "\n",
    "Using `resampled_predictions` from Question 19, generate a 99% confidence interval for Evan's predicted career lengths. **(4 Points)**\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_20\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 4\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bound_evan = ...\n",
    "upper_bound_evan = ...\n",
    "\n",
    "# Don't delete/modify the code below in this cell\n",
    "print(f\"99% CI: [{lower_bound_evan}, {upper_bound_evan}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to see a few bootstrapped regression lines, and the predictions they make for a career length from a pick number of 169."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Just run this cell! \n",
    "# You don't need to understand all of what it is doing but you should recognize a lot of the code!\n",
    "lines = Table(['slope','intercept'])\n",
    "x=169\n",
    "for i in np.arange(20):\n",
    "    resamp = nfl.sample(with_replacement=True)\n",
    "    resample_pars = parameters(resamp, \"Pick Number\", \"Career Length\") \n",
    "    slope = resample_pars.item(0)\n",
    "    intercept = resample_pars.item(1)\n",
    "    lines.append([slope, intercept])\n",
    "    \n",
    "lines['prediction at x='+str(x)] = lines.column('slope')*x + lines.column('intercept')\n",
    "xlims = [min(nfl.column(\"Pick Number\")), max(nfl.column(\"Pick Number\"))]\n",
    "left = xlims[0]*lines[0] + lines[1]\n",
    "right = xlims[1]*lines[0] + lines[1]\n",
    "fit_x = x*lines['slope'] + lines['intercept']\n",
    "for i in range(20):\n",
    "    plt.plot(xlims, np.array([left[i], right[i]]), lw=1)\n",
    "    plt.scatter(x, fit_x[i], s=30)\n",
    "plt.ylabel(\"Career Length\");\n",
    "plt.xlabel(\"Pick Number\");\n",
    "plt.title(\"Resampled Regression Lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Question 21\n",
    "\n",
    "Are we guaranteed that residuals from linear regression will be normally distributed, for any dataset? If you think they are, assign `True` to `residuals_normal`, otherwise assign `False` to `residuals_normal`. **(3 Points)**\n",
    "\n",
    "Hint: Remember what the CLT is defined for.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_21\n",
    "manual: false\n",
    "points:\n",
    " - 0\n",
    " - 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_normal = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_21\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "#### Question 22\n",
    "\n",
    "What are some biases in this dataset that may have affected our analysis? Some questions you can ask yourself are: \"is our sample a simple random sample?\" or \"what kind of data are we using/what variables are we dealing with: are they categorical, numerical, or both (both is something like ordinal data)?\". **(5 Points)**\n",
    "\n",
    "*Hint: you might want to revisit the beginning of this assignment to reread how this data/`nfl` table was generated.*\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1_22\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## (OPTIONAL, Out of Scope) Extending Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This following section is completely **optional**, meaning there's no code to be graded/filled in. Just run the cells/explore if you're interested.\n",
    "\n",
    "In the past few weeks you have learned one of the most powerful tools in a data scientist's arsenal: regression. At this point you may be wondering: what do we do when our data is not linear? You have learned that you shouldn't try and force models when they are bad fits: for example, if we detect heteroscedasticity in our residuals plot, we know that linear regression is a bad fit.\n",
    "\n",
    "How can we fit data that is not linear then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's increase our data's complexity a little: instead of linear data, let's look at data that you would naturally model with a parabola instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parabola(x, a=1, b=0, c=0):\n",
    "    random_noise = np.random.normal(size=len(x)) * 3\n",
    "    return  a*(x**2) + b*(x) + c + random_noise\n",
    "\n",
    "size = 500\n",
    "x_values = np.random.uniform(-5, 10, size=size)\n",
    "y_values = parabola(x_values, a=2, b=-3, c=5)\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Y\", y_values).scatter(\"X\",\"Y\", fit_line=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that our line of best fit is a poor match for this data. Let's look at the residual plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(slope, intercept):\n",
    "    predicted_y = slope * x_values + intercept\n",
    "    errors = y_values - predicted_y\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "\n",
    "slope_and_intercept = minimize(mse, smooth=True)\n",
    "predicted_y = slope_and_intercept.item(0) * x_values + slope_and_intercept.item(1)\n",
    "residuals = y_values - predicted_y\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Residuals\",residuals).scatter(\"X\", \"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our residuals clearly have a pattern, confirming that linear regression is a bad fit for this data! In fact, our residuals actually look like our original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression generates a line that minimizes mean squared error. Using the `minimize` function on the `mse` function does all the work of finding values for us! Can we use `minimize` for more complicated models? Yes! In future data science classes, you will learn how to find these values yourself using the mathematical fields of Linear Algebra (note that it involves lines!) and calculus!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the equation for a line:\n",
    "\n",
    "$$y = ax +b$$\n",
    "\n",
    "There are two parameters here that we can change: $a$, which is the slope, and $b$, which is the intercept.\n",
    "\n",
    "How about the equation for a parabola?\n",
    "\n",
    "$$y = ax^2 + bx + c$$\n",
    "\n",
    "Now there are three parameters, $a,b,c$.\n",
    "\n",
    "Let's change our mse function to incorporate these three parameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_parabola(a, b, c):\n",
    "    predicted_y = a * (x_values**2) + b * (x_values) + c\n",
    "    errors = y_values - predicted_y\n",
    "    return np.mean(errors**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function still returns the mean squared error of our predicted curve, just our curve is now a parabola with the parameters `a`, `b`, and `c`. Let's try and minimize this function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = minimize(mse_parabola, smooth=True)\n",
    "a = params.item(0)\n",
    "b = params.item(1)\n",
    "c = params.item(2)\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot our new curve with these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_range = np.linspace(-5, 10, 1000)\n",
    "predicted_y = a * (x_values_range**2) + b * (x_values_range) + c\n",
    "\n",
    "Table().with_columns(\"X\", x_values, \"Y\", y_values).scatter(\"X\", \"Y\")\n",
    "plt.plot(x_values_range, predicted_y, color='gold', markersize=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our curve looks like a much better fit now! Let's double check the residuals plot to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_values - (a * (x_values**2) + b * (x_values) + c)\n",
    "Table().with_columns(\"X\", x_values, \"Residuals\", residuals).scatter(\"X\", \"Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A formless cloud, excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What else can the method of least squares do?\n",
    "\n",
    "Can we predict a single variable based on the values of two other variables? Right now, we don't have a way of doing that. \n",
    "\n",
    "If you look at the previous example, you could say that the $x^2$ term is actually a second variable.\n",
    "\n",
    "Let's generate a dataset to work with. We are going to try and predict `z` based on `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_range = np.linspace(-5, 10, 1000)\n",
    "\n",
    "x = 0.5 * np.random.uniform(-5, 10, size=size) + 3\n",
    "y = np.random.uniform(-5, 10, size=size) - 1\n",
    "z = 3*x  + (-2*y) -4 + np.random.normal(size=size)\n",
    "\n",
    "data = Table().with_columns(\"x\", x, \"y\", y, \"z\", z)\n",
    "data.scatter(\"x\", \"y\")\n",
    "data.scatter(\"x\", \"z\")\n",
    "data.scatter(\"y\", \"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `x` and `y` would both be very helpful to predict `z` by themselves! However, if we combined them we could predict `z` even better. Since our goal is to minimize mean squared error, let's find the mean squared error of the models that only use `x` and `y` by themselves (using an intercept)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def su(x):\n",
    "    return (x-np.mean(x)) / np.std(x)\n",
    "def r(x, y):\n",
    "    return np.mean(su(x) * su(y))\n",
    "\n",
    "def mse_x(slope, intercept):\n",
    "    predicted_z = slope * x + intercept\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "def mse_y(slope, intercept):\n",
    "    predicted_z = slope * y + intercept\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "\n",
    "slope_and_intercept_x = minimize(mse_x, smooth=True)\n",
    "predicted_z_x = slope_and_intercept_x.item(0) * x + slope_and_intercept_x.item(1)\n",
    "residuals_x = z - predicted_z_x\n",
    "\n",
    "Table().with_columns(\"X\", x, \"Residuals for X Model\", residuals_x).scatter(\"X\", \"Residuals for X Model\")\n",
    "\n",
    "slope_and_intercept_y = minimize(mse_y, smooth=True)\n",
    "predicted_z_y = slope_and_intercept_y.item(0) * y + slope_and_intercept_y.item(1)\n",
    "residuals_y = z - predicted_z_y\n",
    "\n",
    "Table().with_columns(\"Y\", y, \"Residuals for Y Model\", residuals_y).scatter(\"Y\", \"Residuals for Y Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the residual plots show no trend, so using these `x` or `y` by themselves would work, but how good are these models? Let's calculate their actual mse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_only_mse = mse_x(slope_and_intercept_x.item(0), slope_and_intercept_x.item(1))\n",
    "y_only_mse = mse_y(slope_and_intercept_y.item(0), slope_and_intercept_y.item(1))\n",
    "\n",
    "print(f\"X only model MSE: {x_only_mse}, Y only model MSE: {y_only_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the y only model has lower MSE, so we should try and use that if we can only use `x` or `y`. \n",
    "\n",
    "Instead, let's try to build a model that is a combination of `x`, `y` and an intercept `c` to predict `z`!\n",
    "\n",
    "$$z = ax + by +c$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_both(a, b, c):\n",
    "    predicted_z = (a * x) + (b * y) + c\n",
    "    errors = z - predicted_z\n",
    "    return np.mean(errors**2)\n",
    "\n",
    "slope_and_intercept_both = minimize(mse_both, smooth=True)\n",
    "predicted_z = (slope_and_intercept_both.item(0) * x) + (slope_and_intercept_both.item(1) * y) + slope_and_intercept_both.item(2)\n",
    "residuals = z - predicted_z\n",
    "\n",
    "Table().with_columns(\"X\", x, \"Residuals for Full Model\", residuals).scatter(\"X\", \"Residuals for Full Model\")\n",
    "Table().with_columns(\"Y\", x, \"Residuals for Full Model\", residuals).scatter(\"Y\", \"Residuals for Full Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is also a good fit looking at the residuals with respect to both `x` and `y`! What is this model's mse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_mse = mse_both(slope_and_intercept_both.item(0), slope_and_intercept_both.item(1), slope_and_intercept_both.item(2))\n",
    "\n",
    "print(f\"X only model MSE: {x_only_mse}, Y only model MSE: {y_only_mse}, Both X and Y MSE: {full_model_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That MSE is much lower! We should definitely use this model instead of either the x only or y only model independently!\n",
    "Let's try and visualize what this model looks like with a 3D graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "fig = plt.figure(figsize=(10,7));\n",
    "ax = fig.add_subplot(111, projection='3d');\n",
    "ax.scatter(x, y, z);\n",
    "ax.set_xlabel('X');\n",
    "ax.set_ylabel('Y');\n",
    "ax.set_zlabel('Z');\n",
    "\n",
    "ax.scatter(x,y,predicted_z)\n",
    "ax.view_init(elev=20, azim=70);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we start working in more dimensions, visualization becomes increasingly difficult and useless. Instead of predicting a line, our prediction is actually a plane of values (the red values)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
